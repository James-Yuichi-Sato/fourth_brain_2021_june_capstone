{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j-wh0-R8nIvS",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "S_kef3gWlciz"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "#!pip install --upgrade fastapi ffmpeg uvicorn python-multipart tensorflow-gpu scikit-image imutils wandb tensorflow_hub Pillow pyyaml\n",
    "\n",
    "from fastapi import FastAPI, File, UploadFile\n",
    "from skimage.metrics import structural_similarity as compare_ssim\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import ffmpeg, shutil, glob\n",
    "\n",
    "import multiprocessing as mp\n",
    "\n",
    "from google.cloud import storage\n",
    "import nest_asyncio, uvicorn, os, pathlib\n",
    "import yaml\n",
    "import cv2, wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yFaiDWdISXGf",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Set Up Google Cloud Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QMbfPM4GSgYt",
    "tags": []
   },
   "source": [
    "## Set Up Google Cloud Project and Model Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "2bjDmnc5SbHq"
   },
   "outputs": [],
   "source": [
    "location = 'james-mlsys' # Model Storage Bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h4nk8gw3VHwz",
    "tags": []
   },
   "source": [
    "## Create Storage Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "R5BDNjqAVKun"
   },
   "outputs": [],
   "source": [
    "storage_client = storage.Client()\n",
    "\n",
    "bucket = storage_client.bucket(location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ONo4xnfLS0wX",
    "tags": []
   },
   "source": [
    "## Double Check Cloud Bucket (Development Code Only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m4yUDLqHS0VH",
    "outputId": "40c1f26c-4235-441e-d2d0-5a7db2c34e87"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "blobs = storage_client.list_blobs(location)\n",
    "for blob in blobs:\n",
    "    print(blob.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iZCVJpk3H3Ij",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# WandB Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "6JDy6oOTH5v8"
   },
   "outputs": [],
   "source": [
    "def init_wandb(project_name):\n",
    "   global wandb_project\n",
    "   wandb_project = str(project_name)\n",
    "   wandb.init(project=wandb_project, sync_tensorboard=True)\n",
    "   return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KxBHkID8TdsN",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Set Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "q44f0uKITftp"
   },
   "outputs": [],
   "source": [
    "def set_bucket(in_location):\n",
    "    global location \n",
    "    location = str(in_location)\n",
    "    global bucket\n",
    "    bucket = storage_client.bucket(location)\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ia1dFbYETDJB",
    "tags": []
   },
   "source": [
    "# Split Video to Frames and Upload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Download Video to Local Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_video(video_name, extension, origin_folder, dest_folder):\n",
    "    print(\"Checking if video already downloaded\", end=\"\\r\")\n",
    "    if os.path.exists(dest_folder + '/' + video_name + '.' + extension):\n",
    "        text_output = f'Video: {video_name}.{extension} already downloaded. Skipping Download.'\n",
    "        print(text_output)\n",
    "        return\n",
    "    try:\n",
    "        os.mkdir(str(dest_folder))\n",
    "    except:\n",
    "        text_output = f'Folder: {dest_folder} already exists.          '\n",
    "        print(text_output)\n",
    "    def_location = f'{origin_folder}/{video_name}.{extension}'\n",
    "    def_text = f'{origin_folder}_{video_name}.{extension}'\n",
    "    text_output = f'Downloading: {def_location}'\n",
    "    print(text_output)\n",
    "    blob = bucket.blob(def_location)\n",
    "    blob.download_to_filename(def_text)\n",
    "    def_destination = f'{dest_folder}/{video_name}.{extension}'\n",
    "    shutil.move(def_text, def_destination)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Break down video to frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_video_frames(video_name, extension, source_folder, dest_folder):\n",
    "    print(\"Checking if video already split\", end=\"\\r\")\n",
    "    path = f'{dest_folder}/frame00001.png'\n",
    "    if os.path.exists(path):\n",
    "        text_output = f'Video: {video_name} already downloaded. Skipping Download.'\n",
    "        print(text_output)\n",
    "        return\n",
    "    try:\n",
    "        os.mkdir(str(dest_folder))\n",
    "    except:\n",
    "        text_output = f'Folder: {dest_folder} already exists.'\n",
    "        print(text_output)\n",
    "    video_location = f'{source_folder}/{video_name}.{extension}'\n",
    "    video_capture = cv2.VideoCapture(video_location)\n",
    "    saved_frame_name = 1\n",
    "\n",
    "    while True:\n",
    "        print(\"Frame: \" + format(saved_frame_name, '05d'), end=\"\\r\")\n",
    "        success, frame = video_capture.read()\n",
    "\n",
    "        if success:\n",
    "            cv2.imwrite(f\"{str(dest_folder)}/frame{format(saved_frame_name, '05d')}.png\", frame)\n",
    "            saved_frame_name += 1\n",
    "        else:\n",
    "            break\n",
    "    print(\"Done                       \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Upload Video Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_frames(folder_name, extension):\n",
    "    files=sorted(glob.glob(f'{folder_name}/*.{extension}'))\n",
    "    #files=files[1:]\n",
    "    \n",
    "    print(\"Uploading Frames\")\n",
    "    for i in range(len(files)):\n",
    "        print(files[i] + \"             \", end=\"\\r\")\n",
    "        blob = bucket.blob(folder_name + \"/\" + files[i])\n",
    "        blob.upload_from_filename(folder_name + \"/\" + files[i])\n",
    "        \n",
    "    print(\"Done Uploading               \", end=\"\\r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# SSIM Compare Video Frames for Novel Frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Remove Blurry Images from Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Calculate Blurriness using Laplacian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variance_of_laplacian(image):\n",
    "    # compute the Laplacian of the image and then return the focus\n",
    "    # measure, which is simply the variance of the Laplacian\n",
    "    return cv2.Laplacian(image, cv2.CV_64F).var()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Remove Blurry Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallelized_remove_blurry(file):\n",
    "    print(file + \"             \", end=\"\\r\")\n",
    "    img=cv2.imread(file)\n",
    "    img_gray=cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    blurriness=variance_of_laplacian(img_gray)\n",
    "    return blurriness\n",
    "\n",
    "def remove_blurry_images(folder_name, extension):\n",
    "    files=sorted(glob.glob(f'{folder_name}/*.{extension}'))\n",
    "    \n",
    "    #blurriness = np.zeros(len(files))\n",
    "    \n",
    "    print(\"Calculating Average Blurriness\")\n",
    "    \n",
    "    # Parallelize\n",
    "    pool = mp.Pool(mp.cpu_count())\n",
    "    \n",
    "    blurriness = [pool.apply(parallelized_remove_blurry, args=(file,)) for file in files]\n",
    "\n",
    "    pool.close()    \n",
    "        \n",
    "    #for i in range(len(files)):\n",
    "    #    print(files[i] + \"             \", end=\"\\r\")\n",
    "    #    img=cv2.imread(files[i])\n",
    "    #    img_gray=cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    #    blurriness[i]=variance_of_laplacian(img_gray)\n",
    "    #    wandb.log({'Individual Laplacian': blurriness[i]})\n",
    "    \n",
    "    median_blur = np.median(blurriness)\n",
    "    min_blur = np.min(blurriness)\n",
    "    max_blur = np.max(blurriness)\n",
    "    wandb.log({'Individual Laplacian': blurriness, 'Batch Median Laplacian': median_blur})\n",
    "    print(\"Median Blur (Laplacian Variance): \" + str(median_blur))\n",
    "    blur_cutoff = median_blur*1.05 #+ ((1-average_blur)*0.1)\n",
    "    print(\"Blur Cutoff (Laplacian Variance): \" + str(blur_cutoff))\n",
    "    \n",
    "    print(\"Removing Noisy Images\")\n",
    "    \n",
    "    count = 0\n",
    "    for i in range(len(files)):\n",
    "        if blurriness[i] > blur_cutoff:\n",
    "            #print(\"Deleting \" + files[i] + \" - Laplacian Noisiness: \" + str(blurriness[i]))\n",
    "            os.remove(files[i])\n",
    "            count += 1\n",
    "    blur_ratio = count/len(files)\n",
    "    wandb.log({'Noisy Frame Ratio': blur_ratio})\n",
    "    print(f\"Done Checking Frames, {count} frames removed.                 \")\n",
    "    return {'Total Original Frames': len(files), 'Removed Blurry Frames': count, 'Median Laplacian Variance': median_blur, 'Minimum Laplacian Variance': min_blur, 'Maximum Laplacian Variance': max_blur, 'Noisy Frame Ratio': blur_ratio}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Deduplicate Similar Frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Similarity Between Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_images(image1, image2):\n",
    "    image_gray1 = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)\n",
    "    image_gray2 = cv2.cvtColor(image2, cv2.COLOR_BGR2GRAY)\n",
    "    try:\n",
    "        diff, _ = compare_ssim(image_gray1, image_gray2, full=True)\n",
    "    except:\n",
    "        image_gray2 = cv2.resize(image_gray2, image_gray1.shape, interpolation = cv2.INTER_AREA)\n",
    "        diff, _ = compare_ssim(image_gray1, image_gray2, full=True)\n",
    "    return diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallel_remove_duplicates(i, files):\n",
    "    image1 = cv2.imread(files[i])\n",
    "    image2 = cv2.imread(files[i+1])\n",
    "    try:\n",
    "        diff = compare_images(image1, image2)\n",
    "    except:\n",
    "        image2 = cv2.resize(image2, (image1.shape[1], image1.shape[0]), interpolation = cv2.INTER_AREA)\n",
    "        diff = compare_images(image1, image2)\n",
    "    print(str(diff), end=\"\\r\")\n",
    "    return diff\n",
    "    \n",
    "\n",
    "def remove_duplicates(folder_name, extension):\n",
    "    files=sorted(glob.glob(f'{folder_name}/*.{extension}'))\n",
    "    print(\"Removing Duplicate and Highly Similar Frames\\nCalculating Frame Similarities\")\n",
    "    \n",
    "    #diff = np.zeros(len(files)-1)    \n",
    "    \n",
    "    # Parallelize\n",
    "    pool = mp.Pool(mp.cpu_count())\n",
    "\n",
    "    diff = [pool.apply(parallel_remove_duplicates, args=(i, files)) for i in range(len(files)-1)]\n",
    "\n",
    "    pool.close()   \n",
    "    \n",
    "    #for i in range(len(files)-1):\n",
    "    #    image1 = cv2.imread(files[i])\n",
    "    #    image2 = cv2.imread(files[i+1])\n",
    "    #    try:\n",
    "    #        diff[i] = compare_images(image1, image2)\n",
    "    #    except:\n",
    "    #        image2 = cv2.resize(image2, (image1.shape[1], image1.shape[0]), interpolation = cv2.INTER_AREA)\n",
    "    #        diff[i] = compare_images(image1, image2)\n",
    "    #    wandb.log({'Individual Frame Similarities': diff[i]})\n",
    "    #    print(str(diff[i]), end=\"\\r\")\n",
    "    \n",
    "    median_diff = np.median(diff)\n",
    "    wandb.log({'Individual Frame Similarities': diff, 'Batch Median Frame Similarity': median_diff})\n",
    "    \n",
    "    diff_cutoff = median_diff*1.05\n",
    "    \n",
    "    if diff_cutoff < 0.95:\n",
    "        diff_cutoff = 0.95\n",
    "        \n",
    "    print(\"Similarity Cutoff (OpenCV Compare Images): \" + str(diff_cutoff))\n",
    "    print(\"Removing Duplicate Images\")\n",
    "    \n",
    "    count = 0\n",
    "    for i in range(len(diff)):\n",
    "        if diff[i] > 0.99:\n",
    "            #print(\"Deleting \" + files[i] + \" - Similarity: \" + str(diff[i]), end=\"\\r\")\n",
    "            os.remove(files[i])\n",
    "            wandb.log({'Duplicates Similarity': diff})\n",
    "            count += 1\n",
    "        \n",
    "    duplicate_ratio = count/len(files)\n",
    "    wandb.log({'Batch Duplicate Remove Ratio': duplicate_ratio})\n",
    "    print(\"Done Checking Frames, \" + str(count) + \" frames removed.\")\n",
    "    return {'Removed Duplicate Frames': count, 'Median Frame Similarity': median_diff, 'Duplicate Frame Ratio': duplicate_ratio}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Get Insight into the Dataset using Faster RCNN Resnet50 COC0 2018/01/28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-01 03:24:08.874208: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-01 03:24:09.018450: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-01 03:24:09.019374: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-01 03:24:09.021536: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-10-01 03:24:09.022150: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-01 03:24:09.023002: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-01 03:24:09.023873: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-01 03:24:11.537512: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-01 03:24:11.538429: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-01 03:24:11.539274: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-01 03:24:11.540146: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10819 MB memory:  -> device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7\n",
      "2021-10-01 03:24:11.637254: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    }
   ],
   "source": [
    "model_url = 'http://download.tensorflow.org/models/object_detection/faster_rcnn_resnet50_coco_2018_01_28.tar.gz'\n",
    "base_url = os.path.dirname(model_url)+\"/\"\n",
    "model_file = os.path.basename(model_url)\n",
    "model_name = os.path.splitext(os.path.splitext(model_file)[0])[0]\n",
    "model_dir = tf.keras.utils.get_file(fname=model_name, origin=base_url + model_file, untar=True)\n",
    "model_dir = pathlib.Path(model_dir)/\"saved_model\"\n",
    "model = tf.saved_model.load(str(model_dir))\n",
    "model = model.signatures['serving_default']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_LABELS = {1: \"person\", 2: \"bicycle\", 3: \"car\", 4: \"motorcycle\", 5: \"airplane\", 6: \"bus\", 7: \"train\", 8: \"truck\", 9: \"boat\", 10: \"traffic light\", 11: \"fire hydrant\", 13: \"stop sign\", 14: \"parking meter\", 15: \"bench\", 16: \"bird\", 17: \"cat\", 18: \"dog\", 19: \"horse\", 20: \"sheep\", 21: \"cow\", 22: \"elephant\", 23: \"bear\", 24: \"zebra\", 25: \"giraffe\", 27: \"backpack\", 28: \"umbrella\", 31: \"handbag\", 32: \"tie\", 33: \"suitcase\", 34: \"frisbee\", 35: \"skis\", 36: \"snowboard\", 37: \"sports ball\", 38: \"kite\", 39: \"baseball bat\", 40: \"baseball glove\", 41: \"skateboard\", 42: \"surfboard\", 43: \"tennis racket\", 44: \"bottle\", 46: \"wine glass\", 47: \"cup\", 48: \"fork\", 49: \"knife\", 50: \"spoon\", 51: \"bowl\", 52: \"banana\", 53: \"apple\", 54: \"sandwich\", 55: \"orange\", 56: \"broccoli\", 57: \"carrot\", 58: \"hot dog\", 59: \"pizza\", 60: \"donut\", 61: \"cake\", 62: \"chair\", 63: \"couch\", 64: \"potted plant\", 65: \"bed\", 67: \"dining table\", 70: \"toilet\", 72: \"tv\", 73: \"laptop\", 74: \"mouse\", 75: \"remote\", 76: \"keyboard\", 77: \"cell phone\", 78: \"microwave\", 79: \"oven\", 80: \"toaster\", 81: \"sink\", 82: \"refrigerator\", 84: \"book\", 85: \"clock\", 86: \"vase\", 87: \"scissors\", 88: \"teddy bear\", 89: \"hair drier\", 90: \"toothbrush\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_objects(image):\n",
    "    img = Image.open(image)\n",
    "    input_tensor = tf.convert_to_tensor(img)\n",
    "    input_tensor = input_tensor[tf.newaxis,...]\n",
    "    output_dict = model(input_tensor)\n",
    "    num_detections = int(output_dict.pop('num_detections'))\n",
    "    output_dict = {key:value[0, :num_detections].numpy() for key,value in output_dict.items()}\n",
    "    classes = output_dict['detection_classes'].astype(np.int64)\n",
    "    class_names = [None] * len(classes)\n",
    "    for i in range(len(classes)):\n",
    "        class_names[i]=CLASS_LABELS[classes[i]]\n",
    "    output = Counter(class_names)\n",
    "    wandb.log({'Detections per Image': num_detections})\n",
    "    return {'Objects Detected':dict(output), 'Number of Detections': num_detections}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_file(folder_name, extension):\n",
    "    detect_list = []\n",
    "    for file in sorted(glob.glob(f'{folder_name}/*.{extension}')):\n",
    "        print(f'Detecting on Image: {file}', end = '\\r')\n",
    "        output = {'Frame': file}\n",
    "        output.update(detect_objects(file))\n",
    "        detect_list.append(output)\n",
    "    return {'Classification Information': detect_list}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Full Video Analysis and Upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_video(video_name, bucket_location, extension, upload_frames = True):\n",
    "    folder_name = video_name\n",
    "    yaml_val = {'Video': f'{video_name}.{extension}'}\n",
    "    download_video(video_name, extension, bucket_location, folder_name)\n",
    "    frames_folder = f'{video_name}_frames'\n",
    "    split_video_frames(video_name, extension, folder_name, frames_folder)\n",
    "    yaml_val.update(remove_blurry_images(frames_folder, 'png'))\n",
    "    yaml_val.update(remove_duplicates(frames_folder, 'png'))\n",
    "    yaml_val.update(detect_file(frames_folder, 'png'))\n",
    "    f = open(f'{video_name}.yaml', \"w\")\n",
    "    yaml.dump(yaml_val, f, default_flow_style=False)\n",
    "    f.close()\n",
    "    # Upload yaml\n",
    "    blob = bucket.blob(f'{video_name}.yaml')\n",
    "    blob.upload_from_filename(f'{video_name}.yaml')\n",
    "    if upload_frames == True:\n",
    "        upload_frames(frame_folder, 'png')\n",
    "    shutil.rmtree(folder_name)\n",
    "    shutil.rmtree(frames_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video: video_0001.mp4 already downloaded. Skipping Download.\n",
      "Video: video_0001 already downloaded. Skipping Download.\n",
      "Calculating Average Blurriness\n",
      "Median Blur (Laplacian Variance): 77.59506591796044\n",
      "Blur Cutoff (Laplacian Variance): 81.47481921385847\n",
      "Removing Noisy Images\n",
      "Done Checking Frames, 1 frames removed.                 \n",
      "Removing Duplicate and Highly Similar Frames\n",
      "Calculating Frame Similarities\n",
      "Similarity Cutoff (OpenCV Compare Images): 1.0421769452679859\n",
      "Removing Duplicate Images\n",
      "Done Checking Frames, 338 frames removed.\n",
      "Detecting on Image: video_0001_frames/frame00600.png\r"
     ]
    }
   ],
   "source": [
    "clean_video(\"video_0001\",\"JAAD_clips\",\"mp4\",upload_frames = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Sequence Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallized_download(blob, folder_name):\n",
    "    filename = blob.name.replace('/', '_') \n",
    "    print(f'Downloading: {filename}', end = '\\r')\n",
    "    blob.download_to_filename(filename) \n",
    "    new_filename = blob.name[len(folder_name):]\n",
    "    shutil.move(filename, folder_name + new_filename)\n",
    "    \n",
    "def download_images(folder_name):\n",
    "    print(\"Checking if folder already downloaded\", end=\"\\r\")\n",
    "    if os.path.exists(folder_name):\n",
    "        print(\"Folder \" + folder_name + \" already downloaded                                                     \")\n",
    "        return\n",
    "    print(\"Downloading: \" + str(folder_name))\n",
    "    os.mkdir(str(folder_name))\n",
    "    os.mkdir(str(folder_name)+'/images')\n",
    "    os.mkdir(str(folder_name)+'/labels')\n",
    "    os.mkdir(str(folder_name)+'/labels/car')\n",
    "    os.mkdir(str(folder_name)+'/labels/cyclist')\n",
    "    os.mkdir(str(folder_name)+'/labels/pedestrian')\n",
    "    blobs = storage_client.list_blobs(location, prefix = folder_name)\n",
    "    \n",
    "    # Parallelize\n",
    "    pool = mp.Pool(mp.cpu_count())\n",
    "\n",
    "    [pool.apply(parallelized_download, args=(blob, folder_name)) for blob in blobs]\n",
    "\n",
    "    pool.close()    \n",
    "    \n",
    "    #for blob in blobs:\n",
    "    #    filename = blob.name.replace('/', '_') \n",
    "    #    print(filename, end = '\\r')\n",
    "    #    blob.download_to_filename(filename) \n",
    "    #    new_filename = blob.name[len(folder_name):]\n",
    "    #    shutil.move(filename, \"kitti\" + new_filename)\n",
    "    #    #print(blob.name, end=\"\\r\")\n",
    "    #    #blob.download_to_filename(folder_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Images Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_images(folder_name, extension, upload_frames=False):\n",
    "    folder_name = str(folder_name)\n",
    "    yaml_val = {'Folder': folder_name}\n",
    "    download_images(folder_name)\n",
    "    image_folder = f'{folder_name}/images'\n",
    "    yaml_val.update(remove_blurry_images(image_folder, extension))\n",
    "    yaml_val.update(remove_duplicates(image_folder, extension))\n",
    "    yaml_val.update(detect_file(image_folder, extension))\n",
    "    f = open(f'{folder_name}.yaml', \"w\")\n",
    "    yaml.dump(yaml_val, f, default_flow_style=False)\n",
    "    f.close()\n",
    "    print(f'YAML File: {folder_name}.yaml created')\n",
    "    # Upload yaml\n",
    "    blob = bucket.blob(f'{folder_name}.yaml')\n",
    "    blob.upload_from_filename(f'{folder_name}.yaml')\n",
    "    if upload_frames == True:\n",
    "        upload_frames(folder_name, 'png')\n",
    "    shutil.rmtree(folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder kitti already downloaded                                                     \n",
      "Calculating Average Blurriness\n",
      "Median Blur (Laplacian Variance): 445.3854210688824\n",
      "Blur Cutoff (Laplacian Variance): 467.65469212232654\n",
      "Removing Noisy Images\n",
      "Done Checking Frames, 937 frames removed.                 \n",
      "Removing Duplicate and Highly Similar Frames\n",
      "Calculating Frame Similarities\n",
      "Similarity Cutoff (OpenCV Compare Images): 0.95\n",
      "Removing Duplicate Images\n",
      "Done Checking Frames, 0 frames removed.\n",
      "Detecting on Image: kitti/images/000001.png\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-01 03:27:25.874250: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detecting on Image: kitti/images/007514.png\r"
     ]
    }
   ],
   "source": [
    "clean_images('kitti', 'png', upload_frames = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjamesysato\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.3 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.2<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">devoted-puddle-17</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/jamesysato/james-mlsys\" target=\"_blank\">https://wandb.ai/jamesysato/james-mlsys</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/jamesysato/james-mlsys/runs/1a6foz51\" target=\"_blank\">https://wandb.ai/jamesysato/james-mlsys/runs/1a6foz51</a><br/>\n",
       "                Run data is saved locally in <code>/home/jupyter/fourth_brain_2021_june_capstone/wandb/run-20211001_032420-1a6foz51</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_wandb(location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze Entire Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def clean_entire_bucket_videos():\n",
    "#    blobs = storage_client.list_blobs(location)\n",
    "#    for blob in blobs:\n",
    "#        clean_video(blob.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V8Bqr3D6ERcw"
   },
   "source": [
    "# FastAPI Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "wFehIelzjo0E"
   },
   "outputs": [],
   "source": [
    "app = FastAPI()\n",
    "\n",
    "@app.on_event(\"startup\")\n",
    "def start_wandb():\n",
    "    init_wandb(location)\n",
    "    return {'message': ('Weights and Balances Started as project: ' + wandb_project)}\n",
    "\n",
    "@app.get('/')\n",
    "def index():\n",
    "    return {'message': 'This is the homepage of the model, add \\'/docs\\' to the end of the URL to access FastAPI to make predictions with the model'}\n",
    "\n",
    "@app.get('/set_gcp_bucket')\n",
    "def set_gcp_bucket(string_input):\n",
    "    set_bucket(str(string_input))\n",
    "    return {'message': ('GCP Location Set to: ' + location)}\n",
    "\n",
    "@app.get('/clean_single_video')\n",
    "async def single_clean(video_name, bucket_location, extension, upload_frames):\n",
    "    clean_video(video_name, bucket_location, extension, upload_frames)\n",
    "    #clean_video(str(string_input))\n",
    "    if upload_frames == True:\n",
    "        return {'message': (f'Video: {video_name}.{extension} cleaned and yaml and frames uploaded to gs://{location}/')}\n",
    "    else:\n",
    "        return {'message': (f'Video: {video_name}.{extension} cleaned and yaml uploaded to gs://{location}/')}\n",
    "\n",
    "@app.get('/clean_folder_image_sequence')\n",
    "async def single_folder_imageseq(folder_name, extension, upload_frames):\n",
    "    clean_images(folder_name, extension, upload_frames)\n",
    "    return {'message': (f'Images in folder: {folder_name} cleaned and yaml uploaded to gs://{location}')}\n",
    "\n",
    "#@app.get('/clean_bucket_video')\n",
    "#async def full_clean_video():\n",
    "#    clean_entire_bucket_video()\n",
    "#    return {'message': ('Bucket: ' + location + ' cleaned and uploaded to gs://' + location)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4SAjBQPcFQlK"
   },
   "source": [
    "# Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HhmlEVYQFQRk",
    "outputId": "0819598b-d56a-443b-e6ae-0e54f2133bc5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n",
      "INFO:     Started server process [1360]\n",
      "INFO:     Waiting for application startup.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:260bgigh) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 24394<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/jupyter/fourth_brain_2021_june_capstone/wandb/run-20211001_044845-260bgigh/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/jupyter/fourth_brain_2021_june_capstone/wandb/run-20211001_044845-260bgigh/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Batch Duplicate Remove Ratio</td><td>0.0</td></tr><tr><td>Batch Median Frame Similarity</td><td>0.88907</td></tr><tr><td>Batch Median Laplacian</td><td>128.8135</td></tr><tr><td>Detections per Image</td><td>6</td></tr><tr><td>Noisy Frame Ratio</td><td>0.37619</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Batch Duplicate Remove Ratio</td><td>▁</td></tr><tr><td>Batch Median Frame Similarity</td><td>▁</td></tr><tr><td>Batch Median Laplacian</td><td>▁</td></tr><tr><td>Detections per Image</td><td>▂▄▄▄▃▅▄▄▄▄▄▇▆▃▄▃▄▃▁▂▇▃▄▃▅▅▄▆▄▅▇▇▆▃▅█▆▇▃▃</td></tr><tr><td>Noisy Frame Ratio</td><td>▁</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">honest-sponge-18</strong>: <a href=\"https://wandb.ai/jamesysato/james-mlsys/runs/260bgigh\" target=\"_blank\">https://wandb.ai/jamesysato/james-mlsys/runs/260bgigh</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:260bgigh). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.3 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.2<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">firm-vortex-19</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/jamesysato/james-mlsys\" target=\"_blank\">https://wandb.ai/jamesysato/james-mlsys</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/jamesysato/james-mlsys/runs/134ewzv4\" target=\"_blank\">https://wandb.ai/jamesysato/james-mlsys/runs/134ewzv4</a><br/>\n",
       "                Run data is saved locally in <code>/home/jupyter/fourth_brain_2021_june_capstone/wandb/run-20211001_045328-134ewzv4</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     99.147.232.13:57151 - \"GET /docs HTTP/1.1\" 200 OK\n",
      "INFO:     99.147.232.13:57151 - \"GET /openapi.json HTTP/1.1\" 200 OK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Shutting down\n",
      "INFO:     Waiting for application shutdown.\n",
      "INFO:     Application shutdown complete.\n",
      "INFO:     Finished server process [1360]\n"
     ]
    }
   ],
   "source": [
    "nest_asyncio.apply()\n",
    "wandb.login(relogin=True)\n",
    "uvicorn.run(app, host='0.0.0.0', port=8000)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Capstone.ipynb",
   "provenance": []
  },
  "environment": {
   "name": "tf2-gpu.2-6.m80",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m80"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
