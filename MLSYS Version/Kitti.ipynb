{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j-wh0-R8nIvS"
   },
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "S_kef3gWlciz"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "#!pip install --upgrade fastapi ffmpeg uvicorn python-multipart tensorflow-gpu scikit-image imutils wandb tensorflow_hub Pillow pyyaml\n",
    "\n",
    "from fastapi import FastAPI, File, UploadFile\n",
    "from skimage.metrics import structural_similarity as compare_ssim\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import ffmpeg, shutil\n",
    "\n",
    "from google.cloud import storage\n",
    "import nest_asyncio, uvicorn, os, pathlib\n",
    "import yaml\n",
    "import cv2, wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yFaiDWdISXGf"
   },
   "source": [
    "# Set Up Google Cloud Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QMbfPM4GSgYt"
   },
   "source": [
    "## Set Up Google Cloud Project and Model Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "2bjDmnc5SbHq"
   },
   "outputs": [],
   "source": [
    "location = 'james-mlsys' # Model Storage Bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h4nk8gw3VHwz"
   },
   "source": [
    "## Create Storage Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "R5BDNjqAVKun"
   },
   "outputs": [],
   "source": [
    "storage_client = storage.Client() #.from_service_account_json('gcp-key.json')\n",
    "\n",
    "bucket = storage_client.bucket(location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ONo4xnfLS0wX"
   },
   "source": [
    "## Double Check Cloud Bucket (Development Code Only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m4yUDLqHS0VH",
    "outputId": "40c1f26c-4235-441e-d2d0-5a7db2c34e87"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "blobs = storage_client.list_blobs(location)\n",
    "for blob in blobs:\n",
    "    print(blob.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iZCVJpk3H3Ij"
   },
   "source": [
    "# WandB Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "id": "6JDy6oOTH5v8"
   },
   "outputs": [],
   "source": [
    "def init_wandb(project_name):\n",
    "   global wandb_project\n",
    "   wandb_project = str(project_name)\n",
    "   wandb.init(project=wandb_project, sync_tensorboard=True)\n",
    "   return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KxBHkID8TdsN"
   },
   "source": [
    "# Set File Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "q44f0uKITftp"
   },
   "outputs": [],
   "source": [
    "def set_folder_location(in_location):\n",
    "    global location \n",
    "    location = str(in_location)\n",
    "    global bucket\n",
    "    bucket = storage_client.bucket(location)\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ia1dFbYETDJB"
   },
   "source": [
    "# Split Video to Frames and Upload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Video to Local Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_video(video_name):\n",
    "    print(\"Downloading: \" + str(video_name))\n",
    "    blob = bucket.blob(video_name)\n",
    "    blob.download_to_filename(video_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Break down video to frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_video_frames(video_name):\n",
    "    print(\"Splitting: \" + str(video_name))\n",
    "    folder = video_name[:-4]\n",
    "    try:\n",
    "        shutil.rmtree(str(folder))\n",
    "    except:\n",
    "        pass\n",
    "    os.mkdir(str(folder))\n",
    "    \n",
    "    video_capture = cv2.VideoCapture(str(video_name))\n",
    "    saved_frame_name = 1\n",
    "\n",
    "    while True:\n",
    "        print(\"Frame: \" + format(saved_frame_name, '05d'), end=\"\\r\")\n",
    "        success, frame = video_capture.read()\n",
    "\n",
    "        if success:\n",
    "            cv2.imwrite(f\"{str(folder)}/frame{format(saved_frame_name, '05d')}.png\", frame)\n",
    "            saved_frame_name += 1\n",
    "        else:\n",
    "            break\n",
    "    print(\"Done                       \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload Video Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_frames_from_folder(folder_name):\n",
    "    files=sorted(os.listdir(str(folder_name)))\n",
    "    #files=files[1:]\n",
    "    \n",
    "    print(\"Uploading Frames\")\n",
    "    for i in range(len(files)):\n",
    "        print(files[i] + \"             \", end=\"\\r\")\n",
    "        blob = bucket.blob(folder_name + \"/\" + files[i])\n",
    "        blob.upload_from_filename(folder_name + \"/\" + files[i])\n",
    "        \n",
    "    print(\"Done Uploading               \", end=\"\\r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SSIM Compare Video Frames for Novel Frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Blurry Images from Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Blurriness using Laplacian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variance_of_laplacian(image):\n",
    "    # compute the Laplacian of the image and then return the focus\n",
    "    # measure, which is simply the variance of the Laplacian\n",
    "    return cv2.Laplacian(image, cv2.CV_64F).var()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Blurry Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_blurry_images(folder_name):\n",
    "    files=sorted(os.listdir(str(folder_name)))\n",
    "    files=files[1:]\n",
    "    \n",
    "    blurriness = np.zeros(len(files))\n",
    "    \n",
    "    print(\"Calculating Average Blurriness\")\n",
    "    for i in range(len(files)):\n",
    "        print(files[i] + \"             \", end=\"\\r\")\n",
    "        img=cv2.imread(folder_name+'/'+files[i])\n",
    "        img_gray=cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        blurriness[i]=variance_of_laplacian(img_gray)\n",
    "        wandb.log({'Individual Laplacian': blurriness[i]})\n",
    "    \n",
    "    median_blur = np.median(blurriness)\n",
    "    min_blur = np.min(blurriness)\n",
    "    max_blur = np.max(blurriness)\n",
    "    wandb.log({'Batch Median Laplacian': median_blur})\n",
    "    print(\"Median Blur (Laplacian Variance): \" + str(median_blur))\n",
    "    blur_cutoff = median_blur*1.05 #+ ((1-average_blur)*0.1)\n",
    "    print(\"Blur Cutoff (Laplacian Variance): \" + str(blur_cutoff))\n",
    "    \n",
    "    print(\"Removing Noisy Images\")\n",
    "    \n",
    "    count = 0\n",
    "    for i in range(len(files)):\n",
    "        if blurriness[i] > blur_cutoff:\n",
    "            #print(\"Deleting \" + files[i] + \" - Laplacian Noisiness: \" + str(blurriness[i]))\n",
    "            os.remove(folder_name+'/'+files[i])\n",
    "            count += 1\n",
    "    blur_ratio = count/len(files)\n",
    "    wandb.log({'Noisy Frame Ratio': blur_ratio})\n",
    "    print(\"Done Checking Frames                  \")\n",
    "    return {'Total Original Frames': len(files), 'Removed Blurry Frames': count, 'Median Laplacian Variance': median_blur, 'Minimum Laplacian Variance': min_blur, 'Maximum Laplacian Variance': max_blur, 'Noisy Frame Ratio': blur_ratio}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deduplicate Similar Frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Similarity Between Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_images(image1, image2):\n",
    "    image_gray1 = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)\n",
    "    image_gray2 = cv2.cvtColor(image2, cv2.COLOR_BGR2GRAY)\n",
    "    diff, _ = compare_ssim(image_gray1, image_gray2, full=True)\n",
    "    return diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(folder_name):\n",
    "    files=sorted(os.listdir(str(folder_name)))\n",
    "    files=files[1:]\n",
    "    print(\"Removing Duplicate and Highly Similar Frames\\nCalculating Frame Similarities\")\n",
    "    \n",
    "    diff = np.zeros(len(files)-1)    \n",
    "    \n",
    "    for i in range(len(files)-1):\n",
    "        image1 = cv2.imread(folder_name+'/'+files[i])\n",
    "        image2 = cv2.imread(folder_name+'/'+files[i+1])\n",
    "        diff[i] = compare_images(image1, image2)\n",
    "        wandb.log({'Individual Frame Similarities': diff[i]})\n",
    "        print(str(diff[i]), end=\"\\r\")\n",
    "    \n",
    "    median_diff = np.median(diff)\n",
    "    wandb.log({'Batch Median Frame Similarity': median_diff})\n",
    "    \n",
    "    diff_cutoff = median_diff*1.05\n",
    "    \n",
    "    if diff_cutoff < 0.95:\n",
    "        diff_cutoff = 0.95\n",
    "        \n",
    "    print(\"Similarity Cutoff (OpenCV Compare Images): \" + str(diff_cutoff))\n",
    "    print(\"Removing Duplicate Images\")\n",
    "    \n",
    "    count = 0\n",
    "    for i in range(len(diff)):\n",
    "        if diff[i] > 0.99:\n",
    "            #print(\"Deleting \" + files[i] + \" - Similarity: \" + str(diff[i]), end=\"\\r\")\n",
    "            os.remove(folder_name+'/'+files[i])\n",
    "            wandb.log({'Duplicates Similarity': diff})\n",
    "            count += 1\n",
    "        \n",
    "    duplicate_ratio = count/len(files)\n",
    "    wandb.log({'Batch Duplicate Remove Ratio': duplicate_ratio})\n",
    "    print(\"Done Checking Frames, \" + str(count) + \" frames removed.\")\n",
    "    return {'Removed Duplicate Frames': count, 'Median Frame Similarity': median_diff, 'Duplicate Frame Ratio': duplicate_ratio}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Insight into the Dataset using Faster RCNN Resnet50 COC0 2018/01/28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_url = 'http://download.tensorflow.org/models/object_detection/faster_rcnn_resnet50_coco_2018_01_28.tar.gz'\n",
    "base_url = os.path.dirname(model_url)+\"/\"\n",
    "model_file = os.path.basename(model_url)\n",
    "model_name = os.path.splitext(os.path.splitext(model_file)[0])[0]\n",
    "model_dir = tf.keras.utils.get_file(fname=model_name, origin=base_url + model_file, untar=True)\n",
    "model_dir = pathlib.Path(model_dir)/\"saved_model\"\n",
    "model = tf.saved_model.load(str(model_dir))\n",
    "model = model.signatures['serving_default']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_LABELS = {1: \"person\", 2: \"bicycle\", 3: \"car\", 4: \"motorcycle\", 5: \"airplane\", 6: \"bus\", 7: \"train\", 8: \"truck\", 9: \"boat\", 10: \"traffic light\", 11: \"fire hydrant\", 13: \"stop sign\", 14: \"parking meter\", 15: \"bench\", 16: \"bird\", 17: \"cat\", 18: \"dog\", 19: \"horse\", 20: \"sheep\", 21: \"cow\", 22: \"elephant\", 23: \"bear\", 24: \"zebra\", 25: \"giraffe\", 27: \"backpack\", 28: \"umbrella\", 31: \"handbag\", 32: \"tie\", 33: \"suitcase\", 34: \"frisbee\", 35: \"skis\", 36: \"snowboard\", 37: \"sports ball\", 38: \"kite\", 39: \"baseball bat\", 40: \"baseball glove\", 41: \"skateboard\", 42: \"surfboard\", 43: \"tennis racket\", 44: \"bottle\", 46: \"wine glass\", 47: \"cup\", 48: \"fork\", 49: \"knife\", 50: \"spoon\", 51: \"bowl\", 52: \"banana\", 53: \"apple\", 54: \"sandwich\", 55: \"orange\", 56: \"broccoli\", 57: \"carrot\", 58: \"hot dog\", 59: \"pizza\", 60: \"donut\", 61: \"cake\", 62: \"chair\", 63: \"couch\", 64: \"potted plant\", 65: \"bed\", 67: \"dining table\", 70: \"toilet\", 72: \"tv\", 73: \"laptop\", 74: \"mouse\", 75: \"remote\", 76: \"keyboard\", 77: \"cell phone\", 78: \"microwave\", 79: \"oven\", 80: \"toaster\", 81: \"sink\", 82: \"refrigerator\", 84: \"book\", 85: \"clock\", 86: \"vase\", 87: \"scissors\", 88: \"teddy bear\", 89: \"hair drier\", 90: \"toothbrush\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_objects(image):\n",
    "    img = Image.open(image)\n",
    "    input_tensor = tf.convert_to_tensor(img)\n",
    "    input_tensor = input_tensor[tf.newaxis,...]\n",
    "    output_dict = model(input_tensor)\n",
    "    num_detections = int(output_dict.pop('num_detections'))\n",
    "    output_dict = {key:value[0, :num_detections].numpy() for key,value in output_dict.items()}\n",
    "    classes = output_dict['detection_classes'].astype(np.int64)\n",
    "    class_names = [None] * len(classes)\n",
    "    for i in range(len(classes)):\n",
    "        class_names[i]=CLASS_LABELS[classes[i]]\n",
    "    output = Counter(class_names)\n",
    "    wandb.log({'Detections per Image': num_detections})\n",
    "    return {'Objects Detected':dict(output), 'Number of Detections': num_detections}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_file(folder_name):\n",
    "    detect_list = []\n",
    "    for file in sorted(os.listdir(folder_name)):\n",
    "        output = {'Frame': file[:-4]}\n",
    "        total_location = folder_name+\"/\"+file\n",
    "        output.update(detect_objects(total_location))\n",
    "        detect_list.append(output)\n",
    "    return {'Classification Information': detect_list}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full Video Analysis and Upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_video(video_name):\n",
    "    video_name = str(video_name)\n",
    "    folder_name = str(video_name)[:-4]\n",
    "    yaml_val = {'Video': video_name}\n",
    "    download_video(video_name)\n",
    "    split_video_frames(video_name)\n",
    "    yaml_val.update(remove_blurry_images(folder_name))\n",
    "    yaml_val.update(remove_duplicates(folder_name))\n",
    "    yaml_val.update(detect_file(folder_name))\n",
    "    f = open(folder_name+'/'+folder_name+\".yaml\", \"w\")\n",
    "    yaml.dump(yaml_val, f, default_flow_style=False)\n",
    "    f.close()\n",
    "    upload_frames_from_folder(folder_name)\n",
    "    shutil.rmtree(folder_name)\n",
    "    os.remove(video_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Sequence Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_images(folder_name):\n",
    "    print(\"Checking if folder already downloaded\", end=\"\\r\")\n",
    "    if os.path.exists(folder_name):\n",
    "        print(\"Folder \" + folder_name + \" already downloaded\")\n",
    "        return\n",
    "    print(\"Downloading: \" + str(folder_name))\n",
    "    os.mkdir(str(folder_name))\n",
    "    os.mkdir(str(folder_name)+'/images')\n",
    "    os.mkdir(str(folder_name)+'/labels')\n",
    "    os.mkdir(str(folder_name)+'/labels/car')\n",
    "    os.mkdir(str(folder_name)+'/labels/cyclist')\n",
    "    os.mkdir(str(folder_name)+'/labels/pedestrian')\n",
    "    blobs = storage_client.list_blobs(location, prefix = folder_name)\n",
    "    for blob in blobs:\n",
    "        filename = blob.name.replace('/', '_') \n",
    "        print(filename, end = '\\r')\n",
    "        blob.download_to_filename(filename) \n",
    "        new_filename = blob.name[len(folder_name):]\n",
    "        shutil.move(filename, \"kitti\" + new_filename)\n",
    "        #print(blob.name, end=\"\\r\")\n",
    "        #blob.download_to_filename(folder_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Images Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_images(folder_name):\n",
    "    folder_name = str(folder_name)\n",
    "    yaml_val = {'Folder': folder_name}\n",
    "    download_images(folder_name)\n",
    "    yaml_val.update(remove_blurry_images(folder_name+\"/images\"))\n",
    "    yaml_val.update(remove_duplicates(folder_name+\"/images\"))\n",
    "    yaml_val.update(detect_file(folder_name))\n",
    "    f = open(folder_name+'/'+folder_name+\".yaml\", \"w\")\n",
    "    yaml.dump(yaml_val, f, default_flow_style=False)\n",
    "    f.close()\n",
    "    upload_frames_from_folder(folder_name)\n",
    "    shutil.rmtree(folder_name)\n",
    "    os.remove(video_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder kitti already downloadedloaded\n",
      "Calculating Average Blurriness\n",
      "000010.png             \r"
     ]
    }
   ],
   "source": [
    "clean_images(\"kitti\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_wandb(location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze Entire Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_entire_bucket_videos():\n",
    "    blobs = storage_client.list_blobs(location)\n",
    "    for blob in blobs:\n",
    "        clean_video(blob.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V8Bqr3D6ERcw"
   },
   "source": [
    "# FastAPI Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "wFehIelzjo0E"
   },
   "outputs": [],
   "source": [
    "app = FastAPI()\n",
    "\n",
    "@app.on_event(\"startup\")\n",
    "def start_wandb():\n",
    "    init_wandb(location)\n",
    "    return {'message': ('Weights and Balances Started as project: ' + wandb_project)}\n",
    "\n",
    "@app.get('/')\n",
    "def index():\n",
    "    return {'message': 'This is the homepage of the model, add \\'/docs\\' to the end of the URL to access FastAPI to make predictions with the model'}\n",
    "\n",
    "@app.get('/set_gcp_location')\n",
    "def set_gcp_location(string_input):\n",
    "    set_folder_location(str(string_input))\n",
    "    return {'message': ('GCP Location Set to: ' + location)}\n",
    "\n",
    "@app.get('/clean_single_video')\n",
    "async def single_clean(string_input):\n",
    "    clean_video(str(string_input))\n",
    "    return {'message': ('Video: ' + str(string_input) + ' cleaned and uploaded to gs://' + location + \"/\" + str(string_input))}\n",
    "\n",
    "@app.get('/clean_single_video')\n",
    "async def single_clean(string_input):\n",
    "    clean_images(str(string_input))\n",
    "    return {'message': ('Images in folder: ' + str(string_input) + ' cleaned and uploaded to gs://' + location + \"/\" + str(string_input))}\n",
    "\n",
    "\n",
    "@app.get('/clean_bucket_video')\n",
    "async def full_clean_videl():\n",
    "    clean_entire_bucket_video()\n",
    "    return {'message': ('Bucket: ' + location + ' cleaned and uploaded to gs://' + location)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4SAjBQPcFQlK"
   },
   "source": [
    "# Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HhmlEVYQFQRk",
    "outputId": "0819598b-d56a-443b-e6ae-0e54f2133bc5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter:  ········································\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/jupyter/.netrc\n",
      "INFO:     Started server process [11658]\n",
      "INFO:     Waiting for application startup.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjamesysato\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.2<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">skilled-meadow-1</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/jamesysato/james-mlsys\" target=\"_blank\">https://wandb.ai/jamesysato/james-mlsys</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/jamesysato/james-mlsys/runs/2c24twze\" target=\"_blank\">https://wandb.ai/jamesysato/james-mlsys/runs/2c24twze</a><br/>\n",
       "                Run data is saved locally in <code>/home/jupyter/fourth_brain_2021_june_capstone/wandb/run-20210928_011456-2c24twze</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n"
     ]
    }
   ],
   "source": [
    "nest_asyncio.apply()\n",
    "wandb.login(relogin=True)\n",
    "uvicorn.run(app, host='0.0.0.0', port=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Capstone.ipynb",
   "provenance": []
  },
  "environment": {
   "name": "tf2-gpu.2-6.m80",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m80"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
