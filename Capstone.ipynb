{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j-wh0-R8nIvS"
   },
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "S_kef3gWlciz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fastapi in /opt/conda/lib/python3.7/site-packages (0.68.1)\n",
      "Requirement already satisfied: ffmpeg in /opt/conda/lib/python3.7/site-packages (1.4)\n",
      "Requirement already satisfied: uvicorn in /opt/conda/lib/python3.7/site-packages (0.15.0)\n",
      "Requirement already satisfied: python-multipart in /opt/conda/lib/python3.7/site-packages (0.0.5)\n",
      "Requirement already satisfied: tensorflow-gpu in /opt/conda/lib/python3.7/site-packages (2.6.0)\n",
      "Requirement already satisfied: scikit-image in /opt/conda/lib/python3.7/site-packages (0.18.3)\n",
      "Requirement already satisfied: imutils in /opt/conda/lib/python3.7/site-packages (0.5.4)\n",
      "Requirement already satisfied: wandb in /opt/conda/lib/python3.7/site-packages (0.12.2)\n",
      "Requirement already satisfied: tensorflow_hub in /opt/conda/lib/python3.7/site-packages (0.12.0)\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.7/site-packages (8.3.2)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (5.4.1)\n",
      "Requirement already satisfied: pydantic!=1.7,!=1.7.1,!=1.7.2,!=1.7.3,!=1.8,!=1.8.1,<2.0.0,>=1.6.2 in /opt/conda/lib/python3.7/site-packages (from fastapi) (1.8.2)\n",
      "Requirement already satisfied: starlette==0.14.2 in /opt/conda/lib/python3.7/site-packages (from fastapi) (0.14.2)\n",
      "Requirement already satisfied: click>=7.0 in /opt/conda/lib/python3.7/site-packages (from uvicorn) (8.0.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from uvicorn) (3.7.4.3)\n",
      "Requirement already satisfied: h11>=0.8 in /opt/conda/lib/python3.7/site-packages (from uvicorn) (0.12.0)\n",
      "Requirement already satisfied: asgiref>=3.4.0 in /opt/conda/lib/python3.7/site-packages (from uvicorn) (3.4.1)\n",
      "Requirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.7/site-packages (from python-multipart) (1.15.0)\n",
      "Requirement already satisfied: gast==0.4.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu) (0.4.0)\n",
      "Requirement already satisfied: tensorflow-estimator~=2.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu) (2.6.0)\n",
      "Requirement already satisfied: h5py~=3.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu) (3.1.0)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu) (1.1.2)\n",
      "Requirement already satisfied: numpy~=1.19.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu) (1.19.5)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu) (1.12.1)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu) (3.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.37.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu) (1.38.1)\n",
      "Requirement already satisfied: absl-py~=0.10 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu) (0.13.0)\n",
      "Requirement already satisfied: wheel~=0.35 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu) (0.37.0)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu) (0.2.0)\n",
      "Requirement already satisfied: clang~=5.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu) (5.0)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu) (1.1.0)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu) (3.3.0)\n",
      "Requirement already satisfied: keras~=2.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu) (2.6.0)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu) (1.12)\n",
      "Requirement already satisfied: tensorboard~=2.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu) (2.6.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu) (1.6.3)\n",
      "Requirement already satisfied: scipy>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from scikit-image) (1.7.1)\n",
      "Requirement already satisfied: imageio>=2.3.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image) (2.9.0)\n",
      "Requirement already satisfied: networkx>=2.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image) (2.5)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from scikit-image) (1.1.1)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /opt/conda/lib/python3.7/site-packages (from scikit-image) (2021.8.30)\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image) (3.4.3)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /opt/conda/lib/python3.7/site-packages (from wandb) (2.8.2)\n",
      "Requirement already satisfied: shortuuid>=0.5.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (1.0.1)\n",
      "Requirement already satisfied: configparser>=3.8.1 in /opt/conda/lib/python3.7/site-packages (from wandb) (5.0.2)\n",
      "Requirement already satisfied: subprocess32>=3.5.3 in /opt/conda/lib/python3.7/site-packages (from wandb) (3.5.4)\n",
      "Requirement already satisfied: yaspin>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (2.1.0)\n",
      "Requirement already satisfied: promise<3,>=2.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (2.3)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (1.3.1)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (2.25.1)\n",
      "Requirement already satisfied: pathtools in /opt/conda/lib/python3.7/site-packages (from wandb) (0.1.2)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (5.8.0)\n",
      "Requirement already satisfied: GitPython>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (3.1.18)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from click>=7.0->uvicorn) (4.8.1)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.7/site-packages (from GitPython>=1.0.0->wandb) (4.0.7)\n",
      "Requirement already satisfied: smmap<5,>=3.0.1 in /opt/conda/lib/python3.7/site-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (3.0.5)\n",
      "Requirement already satisfied: cached-property in /opt/conda/lib/python3.7/site-packages (from h5py~=3.1.0->tensorflow-gpu) (1.5.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.3.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from networkx>=2.0->scikit-image) (5.0.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2021.5.30)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (1.26.6)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.6->tensorflow-gpu) (1.8.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.6->tensorflow-gpu) (1.35.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.6->tensorflow-gpu) (57.4.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.6->tensorflow-gpu) (2.0.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.6->tensorflow-gpu) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.6->tensorflow-gpu) (0.6.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.6->tensorflow-gpu) (3.3.4)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow-gpu) (4.2.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow-gpu) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow-gpu) (0.2.7)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow-gpu) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow-gpu) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow-gpu) (3.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->click>=7.0->uvicorn) (3.5.0)\n"
     ]
    }
   ],
   "source": [
    "#%%capture\n",
    "!pip install --upgrade fastapi ffmpeg uvicorn python-multipart tensorflow-gpu scikit-image imutils wandb tensorflow_hub Pillow pyyaml\n",
    "\n",
    "from fastapi import FastAPI, File, UploadFile\n",
    "from skimage.metrics import structural_similarity as compare_ssim\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import ffmpeg, shutil\n",
    "\n",
    "from google.cloud import storage\n",
    "import nest_asyncio, uvicorn, os, pathlib\n",
    "import yaml\n",
    "import cv2, wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yFaiDWdISXGf"
   },
   "source": [
    "# Set Up Google Cloud Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QMbfPM4GSgYt"
   },
   "source": [
    "## Set Up Google Cloud Project and Model Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "2bjDmnc5SbHq"
   },
   "outputs": [],
   "source": [
    "project = 'mlops-content1' # Cloud Project Name\n",
    "location = 'james-mlops-capstone' # Model Storage Bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h4nk8gw3VHwz"
   },
   "source": [
    "## Create Storage Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "R5BDNjqAVKun"
   },
   "outputs": [],
   "source": [
    "storage_client = storage.Client.from_service_account_json('gcp-key.json')\n",
    "\n",
    "bucket = storage_client.bucket(location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ONo4xnfLS0wX"
   },
   "source": [
    "## Double Check Cloud Bucket (Development Code Only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m4yUDLqHS0VH",
    "outputId": "40c1f26c-4235-441e-d2d0-5a7db2c34e87"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "blobs = storage_client.list_blobs(location)\n",
    "for blob in blobs:\n",
    "    print(blob.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iZCVJpk3H3Ij"
   },
   "source": [
    "# WandB Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "6JDy6oOTH5v8"
   },
   "outputs": [],
   "source": [
    "def init_wandb(project_name):\n",
    "   global wandb_project\n",
    "   wandb_project = str(project_name)\n",
    "   wandb.init(project=wandb_project, sync_tensorboard=True)\n",
    "   return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KxBHkID8TdsN"
   },
   "source": [
    "# Set File Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "q44f0uKITftp"
   },
   "outputs": [],
   "source": [
    "def set_folder_location(in_location):\n",
    "    global location \n",
    "    location = str(in_location)\n",
    "    global bucket\n",
    "    bucket = storage_client.bucket(location)\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ia1dFbYETDJB"
   },
   "source": [
    "# Split Video to Frames and Upload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Video to Local Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_video(video_name):\n",
    "    print(\"Downloading: \" + str(video_name))\n",
    "    blob = bucket.blob(video_name)\n",
    "    blob.download_to_filename(video_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Break down video to frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_video_frames(video_name):\n",
    "    print(\"Splitting: \" + str(video_name))\n",
    "    folder = video_name[:-4]\n",
    "    try:\n",
    "        shutil.rmtree(str(folder))\n",
    "    except:\n",
    "        pass\n",
    "    os.mkdir(str(folder))\n",
    "    \n",
    "    video_capture = cv2.VideoCapture(str(video_name))\n",
    "    saved_frame_name = 1\n",
    "\n",
    "    while True:\n",
    "        print(\"Frame: \" + format(saved_frame_name, '05d'), end=\"\\r\")\n",
    "        success, frame = video_capture.read()\n",
    "\n",
    "        if success:\n",
    "            cv2.imwrite(f\"{str(folder)}/frame{format(saved_frame_name, '05d')}.png\", frame)\n",
    "            saved_frame_name += 1\n",
    "        else:\n",
    "            break\n",
    "    print(\"Done                       \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload Video Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_frames_from_folder(folder_name):\n",
    "    files=sorted(os.listdir(str(folder_name)))\n",
    "    #files=files[1:]\n",
    "    \n",
    "    print(\"Uploading Frames\")\n",
    "    for i in range(len(files)):\n",
    "        print(files[i] + \"             \", end=\"\\r\")\n",
    "        blob = bucket.blob(folder_name + \"/\" + files[i])\n",
    "        blob.upload_from_filename(folder_name + \"/\" + files[i])\n",
    "        \n",
    "    print(\"Done Uploading               \", end=\"\\r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SSIM Compare Video Frames for Novel Frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Blurry Images from Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Blurriness using Laplacian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variance_of_laplacian(image):\n",
    "    # compute the Laplacian of the image and then return the focus\n",
    "    # measure, which is simply the variance of the Laplacian\n",
    "    return cv2.Laplacian(image, cv2.CV_64F).var()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Blurry Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_blurry_images(folder_name):\n",
    "    files=sorted(os.listdir(str(folder_name)))\n",
    "    files=files[1:]\n",
    "    \n",
    "    blurriness = np.zeros(len(files))\n",
    "    \n",
    "    print(\"Calculating Average Blurriness\")\n",
    "    for i in range(len(files)):\n",
    "        print(files[i] + \"             \", end=\"\\r\")\n",
    "        img=cv2.imread(folder_name+'/'+files[i])\n",
    "        img_gray=cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        blurriness[i]=variance_of_laplacian(img_gray)\n",
    "        wandb.log({'Individual Laplacian': blurriness[i]})\n",
    "    \n",
    "    median_blur = np.median(blurriness)\n",
    "    min_blur = np.min(blurriness)\n",
    "    max_blur = np.max(blurriness)\n",
    "    wandb.log({'Batch Median Laplacian': median_blur})\n",
    "    print(\"Median Blur (Laplacian Variance): \" + str(median_blur))\n",
    "    blur_cutoff = median_blur*1.05 #+ ((1-average_blur)*0.1)\n",
    "    print(\"Blur Cutoff (Laplacian Variance): \" + str(blur_cutoff))\n",
    "    \n",
    "    print(\"Removing Noisy Images\")\n",
    "    \n",
    "    count = 0\n",
    "    for i in range(len(files)):\n",
    "        if blurriness[i] > blur_cutoff:\n",
    "            #print(\"Deleting \" + files[i] + \" - Laplacian Noisiness: \" + str(blurriness[i]))\n",
    "            os.remove(folder_name+'/'+files[i])\n",
    "            count += 1\n",
    "    blur_ratio = count/len(files)\n",
    "    wandb.log({'Noisy Frame Ratio': blur_ratio})\n",
    "    print(\"Done Checking Frames                  \")\n",
    "    return {'Total Original Frames': len(files), 'Removed Blurry Frames': count, 'Median Laplacian Variance': median_blur, 'Minimum Laplacian Variance': min_blur, 'Maximum Laplacian Variance': max_blur, 'Noisy Frame Ratio': blur_ratio}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deduplicate Similar Frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Similarity Between Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_images(image1, image2):\n",
    "    image_gray1 = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)\n",
    "    image_gray2 = cv2.cvtColor(image2, cv2.COLOR_BGR2GRAY)\n",
    "    diff, _ = compare_ssim(image_gray1, image_gray2, full=True)\n",
    "    return diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(folder_name):\n",
    "    files=sorted(os.listdir(str(folder_name)))\n",
    "    files=files[1:]\n",
    "    print(\"Removing Duplicate and Highly Similar Frames\\nCalculating Frame Similarities\")\n",
    "    \n",
    "    diff = np.zeros(len(files)-1)    \n",
    "    \n",
    "    for i in range(len(files)-1):\n",
    "        image1 = cv2.imread(folder_name+'/'+files[i])\n",
    "        image2 = cv2.imread(folder_name+'/'+files[i+1])\n",
    "        diff[i] = compare_images(image1, image2)\n",
    "        wandb.log({'Individual Frame Similarities': diff[i]})\n",
    "        print(str(diff[i]), end=\"\\r\")\n",
    "    \n",
    "    median_diff = np.median(diff)\n",
    "    wandb.log({'Batch Median Frame Similarity': median_diff})\n",
    "    \n",
    "    diff_cutoff = median_diff*1.05\n",
    "    \n",
    "    if diff_cutoff < 0.95:\n",
    "        diff_cutoff = 0.95\n",
    "        \n",
    "    print(\"Similarity Cutoff (OpenCV Compare Images): \" + str(diff_cutoff))\n",
    "    print(\"Removing Duplicate Images\")\n",
    "    \n",
    "    count = 0\n",
    "    for i in range(len(diff)):\n",
    "        if diff[i] > 0.99:\n",
    "            #print(\"Deleting \" + files[i] + \" - Similarity: \" + str(diff[i]), end=\"\\r\")\n",
    "            os.remove(folder_name+'/'+files[i])\n",
    "            wandb.log({'Duplicates Similarity': diff})\n",
    "            count += 1\n",
    "        \n",
    "    duplicate_ratio = count/len(files)\n",
    "    wandb.log({'Batch Duplicate Remove Ratio': duplicate_ratio})\n",
    "    print(\"Done Checking Frames, \" + str(count) + \" frames removed.\")\n",
    "    return {'Removed Duplicate Frames': count, 'Median Frame Similarity': median_diff, 'Duplicate Frame Ratio': duplicate_ratio}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Insight into the Dataset using Faster RCNN Resnet50 COC0 2018/01/28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-17 21:51:54.982113: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-17 21:51:54.989710: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-17 21:51:54.990332: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-17 21:51:54.991857: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-09-17 21:51:54.992191: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-17 21:51:54.992841: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-17 21:51:54.993407: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-17 21:51:55.544456: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-17 21:51:55.545145: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-17 21:51:55.545768: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-17 21:51:55.546318: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13803 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
      "2021-09-17 21:51:55.598849: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    }
   ],
   "source": [
    "model_url = 'http://download.tensorflow.org/models/object_detection/faster_rcnn_resnet50_coco_2018_01_28.tar.gz'\n",
    "base_url = os.path.dirname(model_url)+\"/\"\n",
    "model_file = os.path.basename(model_url)\n",
    "model_name = os.path.splitext(os.path.splitext(model_file)[0])[0]\n",
    "model_dir = tf.keras.utils.get_file(fname=model_name, origin=base_url + model_file, untar=True)\n",
    "model_dir = pathlib.Path(model_dir)/\"saved_model\"\n",
    "model = tf.saved_model.load(str(model_dir))\n",
    "model = model.signatures['serving_default']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_LABELS = {1: \"person\", 2: \"bicycle\", 3: \"car\", 4: \"motorcycle\", 5: \"airplane\", 6: \"bus\", 7: \"train\", 8: \"truck\", 9: \"boat\", 10: \"traffic light\", 11: \"fire hydrant\", 13: \"stop sign\", 14: \"parking meter\", 15: \"bench\", 16: \"bird\", 17: \"cat\", 18: \"dog\", 19: \"horse\", 20: \"sheep\", 21: \"cow\", 22: \"elephant\", 23: \"bear\", 24: \"zebra\", 25: \"giraffe\", 27: \"backpack\", 28: \"umbrella\", 31: \"handbag\", 32: \"tie\", 33: \"suitcase\", 34: \"frisbee\", 35: \"skis\", 36: \"snowboard\", 37: \"sports ball\", 38: \"kite\", 39: \"baseball bat\", 40: \"baseball glove\", 41: \"skateboard\", 42: \"surfboard\", 43: \"tennis racket\", 44: \"bottle\", 46: \"wine glass\", 47: \"cup\", 48: \"fork\", 49: \"knife\", 50: \"spoon\", 51: \"bowl\", 52: \"banana\", 53: \"apple\", 54: \"sandwich\", 55: \"orange\", 56: \"broccoli\", 57: \"carrot\", 58: \"hot dog\", 59: \"pizza\", 60: \"donut\", 61: \"cake\", 62: \"chair\", 63: \"couch\", 64: \"potted plant\", 65: \"bed\", 67: \"dining table\", 70: \"toilet\", 72: \"tv\", 73: \"laptop\", 74: \"mouse\", 75: \"remote\", 76: \"keyboard\", 77: \"cell phone\", 78: \"microwave\", 79: \"oven\", 80: \"toaster\", 81: \"sink\", 82: \"refrigerator\", 84: \"book\", 85: \"clock\", 86: \"vase\", 87: \"scissors\", 88: \"teddy bear\", 89: \"hair drier\", 90: \"toothbrush\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[\"\", \"person\", \"bicycle\", \"car\", \"motorcycle\", \"airplane\", \"bus\", \"train\", \"truck\", \"boat\", \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\", \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\", \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\", \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\", \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\", \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"couch\", \"potted plant\", \"bed\", \"dining table\", \"toilet\", \"tv\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\", \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\", \"teddy bear\", \"hair drier\", \"toothbrush\", \"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_objects(image):\n",
    "    img = Image.open(image)\n",
    "    input_tensor = tf.convert_to_tensor(img)\n",
    "    input_tensor = input_tensor[tf.newaxis,...]\n",
    "    output_dict = model(input_tensor)\n",
    "    num_detections = int(output_dict.pop('num_detections'))\n",
    "    output_dict = {key:value[0, :num_detections].numpy() for key,value in output_dict.items()}\n",
    "    classes = output_dict['detection_classes'].astype(np.int64)\n",
    "    class_names = [None] * len(classes)\n",
    "    for i in range(len(classes)):\n",
    "        class_names[i]=CLASS_LABELS[classes[i]]\n",
    "    output = Counter(class_names)\n",
    "    wandb.log({'Detections per Image': num_detections})\n",
    "    return {'Objects Detected':dict(output), 'Number of Detections': num_detections}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_file(folder_name):\n",
    "    detect_list = []\n",
    "    for file in sorted(os.listdir(folder_name)):\n",
    "        output = {'Frame': file[:-4]}\n",
    "        total_location = folder_name+\"/\"+file\n",
    "        output.update(detect_objects(total_location))\n",
    "        detect_list.append(output)\n",
    "    return {'Classification Information': detect_list}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full Video Analysis and Upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_video(video_name):\n",
    "    video_name = str(video_name)\n",
    "    folder_name = str(video_name)[:-4]\n",
    "    yaml_val = {'Video': video_name}\n",
    "    download_video(video_name)\n",
    "    split_video_frames(video_name)\n",
    "    yaml_val.update(remove_blurry_images(folder_name))\n",
    "    yaml_val.update(remove_duplicates(folder_name))\n",
    "    yaml_val.update(detect_file(folder_name))\n",
    "    f = open(folder_name+'/'+folder_name+\".yaml\", \"w\")\n",
    "    yaml.dump(yaml_val, f, default_flow_style=False)\n",
    "    f.close()\n",
    "    upload_frames_from_folder(folder_name)\n",
    "    shutil.rmtree(folder_name)\n",
    "    os.remove(video_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze Entire Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_entire_bucket():\n",
    "    blobs = storage_client.list_blobs(location)\n",
    "    for blob in blobs:\n",
    "        clean_video(blob.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V8Bqr3D6ERcw"
   },
   "source": [
    "# FastAPI Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "wFehIelzjo0E"
   },
   "outputs": [],
   "source": [
    "app = FastAPI()\n",
    "\n",
    "@app.on_event(\"startup\")\n",
    "def start_wandb():\n",
    "    init_wandb(location)\n",
    "    return {'message': ('Weights and Balances Started as project: ' + wandb_project)}\n",
    "\n",
    "@app.get('/')\n",
    "def index():\n",
    "    return {'message': 'This is the homepage of the model, add \\'/docs\\' to the end of the URL to access FastAPI to make predictions with the model'}\n",
    "\n",
    "@app.get('/set_gcp_location')\n",
    "def set_gcp_location(string_input):\n",
    "    set_folder_location(str(string_input))\n",
    "    return {'message': ('GCP Location Set to: ' + location)}\n",
    "\n",
    "@app.get('/clean_single_video')\n",
    "async def single_clean(string_input):\n",
    "    clean_video(str(string_input))\n",
    "    return {'message': ('Video: ' + str(string_input) + ' cleaned and uploaded to gs://' + location + \"/\" + str(string_input))}\n",
    "\n",
    "@app.get('/clean_bucket')\n",
    "async def full_clean():\n",
    "    clean_entire_bucket()\n",
    "    return {'message': ('Bucket: ' + location + ' cleaned and uploaded to gs://' + location)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4SAjBQPcFQlK"
   },
   "source": [
    "# Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HhmlEVYQFQRk",
    "outputId": "0819598b-d56a-443b-e6ae-0e54f2133bc5"
   }
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     99.147.232.13:57065 - \"GET /docs HTTP/1.1\" 200 OK\n",
      "INFO:     99.147.232.13:57065 - \"GET /openapi.json HTTP/1.1\" 200 OK\n"
     ]
    }
   ],
   "source": [
    "nest_asyncio.apply()\n",
    "wandb.login(relogin=True)\n",
    "uvicorn.run(app, host='0.0.0.0', port=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Capstone.ipynb",
   "provenance": []
  },
  "environment": {
   "name": "common-cu110.m79",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu110:m79"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
