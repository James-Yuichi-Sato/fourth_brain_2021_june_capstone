{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DG0brT337oQ6"
   },
   "source": [
    "# To-Do List\n",
    "Database\n",
    "\n",
    "Front End\n",
    "\n",
    "Image Quality - How to check\n",
    "\n",
    "skimage.measure compare_SSIM\n",
    "\n",
    "GT quality - Mean pixels strength, pixel mean value\n",
    "\n",
    "Images w/ metadata\n",
    "Metadata - Key Frames - Categories\n",
    "\n",
    "Import batch of frames - Curate Frames - Check Ground Truth - Generate Metadata - Output\n",
    "WandB\n",
    "Flask Front End\n",
    "Image Output\n",
    "\n",
    "scalability\n",
    "\n",
    "wandb - monitor quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j-wh0-R8nIvS"
   },
   "source": [
    "# Import FastAPI, FFmpeg, uvicorn, and JAAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "id": "S_kef3gWlciz"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install fastapi ffmpeg uvicorn JAAD python-multipart tensorflow-gpu scikit-image imutils\n",
    "\n",
    "from fastapi import FastAPI, File, UploadFile\n",
    "import nest_asyncio, uvicorn\n",
    "\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZVbLxspHFhv0"
   },
   "source": [
    "# Import and Set Up WandB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cY78MLJQFuO8"
   },
   "source": [
    "## Import WandB Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "kLHbXSR6FlGo"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install wandb\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CVWMTSiqFwgP"
   },
   "source": [
    "## Log In to WandB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "id": "qpEwDK6CFzDF",
    "outputId": "44ca9a46-61c4-41d0-9f82-eff945e8b7e2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter:  ········································\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/jupyter/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gzit_qslFlvV"
   },
   "source": [
    "# Set up ResNet50 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WRloZF61mh7v",
    "outputId": "86fc5cfb-3f51-49a7-ddc2-4b71fa7774d8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-10 02:31:04.577938: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-10 02:31:04.637083: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2021-09-10 02:31:04.657723: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1835] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2021-09-10 02:31:04.658601: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels.h5\n",
      "102973440/102967424 [==============================] - 1s 0us/step\n",
      "102981632/102967424 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "import numpy as np\n",
    "\n",
    "model = ResNet50(weights='imagenet')\n",
    "\n",
    "# img_path = 'elephant.jpg'\n",
    "# img = image.load_img(img_path, target_size=(224, 224))\n",
    "# x = image.img_to_array(img)\n",
    "# x = np.expand_dims(x, axis=0)\n",
    "# x = preprocess_input(x)\n",
    "\n",
    "# preds = model.predict(x)\n",
    "# decode the results into a list of tuples (class, description, probability)\n",
    "# (one such list for each sample in the batch)\n",
    "# print('Predicted:', decode_predictions(preds, top=3)[0])\n",
    "# Predicted: [(u'n02504013', u'Indian_elephant', 0.82658225), (u'n01871265', u'tusker', 0.1122357), (u'n02504458', u'African_elephant', 0.061040461)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yFaiDWdISXGf"
   },
   "source": [
    "# Set Up Google Cloud Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2lLW9XWyVTqS"
   },
   "source": [
    "## Import Google Cloud Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "DM-j8IKgVWDe"
   },
   "outputs": [],
   "source": [
    "from google.cloud import storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QMbfPM4GSgYt"
   },
   "source": [
    "## Set Up Google Cloud Project and Model Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "2bjDmnc5SbHq"
   },
   "outputs": [],
   "source": [
    "project = 'mlops-content1' # Cloud Project Name\n",
    "location = 'james-mlops-capstone' # Model Storage Bucket\n",
    "model_dir = 'model'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h4nk8gw3VHwz"
   },
   "source": [
    "## Create Storage Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "id": "R5BDNjqAVKun"
   },
   "outputs": [],
   "source": [
    "storage_client = storage.Client.from_service_account_json('james-capstone-key.json')\n",
    "\n",
    "bucket = storage_client.bucket(location)\n",
    "\n",
    "# working_bucket = storage_client.bucket(location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ONo4xnfLS0wX"
   },
   "source": [
    "## Double Check Cloud Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m4yUDLqHS0VH",
    "outputId": "40c1f26c-4235-441e-d2d0-5a7db2c34e87"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "blobs = storage_client.list_blobs(location)\n",
    "for blob in blobs:\n",
    "    print(blob.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iZCVJpk3H3Ij"
   },
   "source": [
    "# WandB Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "6JDy6oOTH5v8"
   },
   "outputs": [],
   "source": [
    "def init_wandb(project_name):\n",
    "   global wandb_project\n",
    "   wandb_project = str(project_name)\n",
    "   wandb.init(project=wandb_project, sync_tensorboard=True)\n",
    "   return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KxBHkID8TdsN"
   },
   "source": [
    "# Set File Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "q44f0uKITftp"
   },
   "outputs": [],
   "source": [
    "def set_folder_location(in_location):\n",
    "   global location \n",
    "   location = str(in_location)\n",
    "   return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ia1dFbYETDJB"
   },
   "source": [
    "# Split Video to Frames and Upload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Video to Local Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_video(video_name):\n",
    "    blob = bucket.blob(video_name)\n",
    "    blob.download_to_filename(video_name)\n",
    "    \n",
    "download_video(\"video_0001.mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Break down video to frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘video_0001’: File exists\n",
      "ffmpeg version 9c33b2f Copyright (c) 2000-2021 the FFmpeg developers\n",
      "  built with gcc 9.3.0 (crosstool-NG 1.24.0.133_b0863d8_dirty)\n",
      "  configuration: --prefix=/opt/conda --cc=/home/conda/feedstock_root/build_artifacts/ffmpeg_1627813612080/_build_env/bin/x86_64-conda-linux-gnu-cc --disable-doc --disable-openssl --enable-avresample --enable-gnutls --enable-gpl --enable-hardcoded-tables --enable-libfreetype --enable-libopenh264 --enable-libx264 --enable-pic --enable-pthreads --enable-shared --enable-static --enable-version3 --enable-zlib --enable-libmp3lame --pkg-config=/home/conda/feedstock_root/build_artifacts/ffmpeg_1627813612080/_build_env/bin/pkg-config\n",
      "  libavutil      56. 51.100 / 56. 51.100\n",
      "  libavcodec     58. 91.100 / 58. 91.100\n",
      "  libavformat    58. 45.100 / 58. 45.100\n",
      "  libavdevice    58. 10.100 / 58. 10.100\n",
      "  libavfilter     7. 85.100 /  7. 85.100\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  7.100 /  5.  7.100\n",
      "  libswresample   3.  7.100 /  3.  7.100\n",
      "  libpostproc    55.  7.100 / 55.  7.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'video_0001.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf56.40.101\n",
      "  Duration: 00:00:20.02, start: 0.000000, bitrate: 2768 kb/s\n",
      "    Stream #0:0(eng): Video: h264 (High) (avc1 / 0x31637661), yuv420p, 1920x1080 [SAR 1:1 DAR 16:9], 2765 kb/s, 29.97 fps, 29.97 tbr, 30k tbn, 59.94 tbc (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (h264 (native) -> png (native))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, image2, to 'video_0001/frame%04d.png':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf58.45.100\n",
      "    Stream #0:0(eng): Video: png, rgb24, 1920x1080 [SAR 1:1 DAR 16:9], q=2-31, 200 kb/s, 29.97 fps, 29.97 tbn, 29.97 tbc (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "      encoder         : Lavc58.91.100 png\n",
      "frame=  600 fps= 20 q=-0.0 Lsize=N/A time=00:00:20.02 bitrate=N/A speed=0.68x    \n",
      "video:645931kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: unknown\n"
     ]
    }
   ],
   "source": [
    "def split_video_frames(video_name):\n",
    "    folder = video_name[:-4]\n",
    "    !mkdir $folder\n",
    "    !ffmpeg -i $video_name $folder/frame%04d.png\n",
    "\n",
    "split_video_frames(\"video_0001.mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload Video Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading Frames\n",
      "Done Uploading               \r"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "def upload_frames_from_folder(folder_name):\n",
    "    folder_name = folder_name + \"/*.png\"\n",
    "    print(\"Uploading Frames\")\n",
    "    for filename in glob.iglob(folder_name):\n",
    "        print(filename, end=\"\\r\")\n",
    "        blob = bucket.blob(filename)\n",
    "        blob.upload_from_filename(filename)\n",
    "    print(\"Done Uploading               \", end=\"\\r\")\n",
    "    \n",
    "upload_frames_from_folder(\"video_0001\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SSIM Compare Video Frames for Novel Frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from skimage.metrics import structural_similarity as compare_ssim\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Blurry Images from Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Blurriness using Laplacian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variance_of_laplacian(image):\n",
    "    # compute the Laplacian of the image and then return the focus\n",
    "    # measure, which is simply the variance of the Laplacian\n",
    "    return cv2.Laplacian(image, cv2.CV_64F).var()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Blurry Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done Checking Frames\n"
     ]
    }
   ],
   "source": [
    "def remove_blurry_images(folder_name):\n",
    "    files=sorted(os.listdir(str(folder_name)))\n",
    "    files=files[1:]\n",
    "    \n",
    "    for file in files:\n",
    "        print(file, end=\"\\r\")\n",
    "        img=cv2.imread(folder_name+'/'+file)\n",
    "        img_gray=cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        blurriness=variance_of_laplacian(img_gray)\n",
    "        if blurriness>100:\n",
    "            os.remove(folder_name+'/'+file)\n",
    "            print(\"Removed: \" + file + \" - Laplace Variance Blurriness: \" + str(blurriness))\n",
    "    print(\"Done Checking Frames\")\n",
    "\n",
    "remove_blurry_images(\"video_0001\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deduplicate Similar Frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Similarity Between Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_images(image1, image2):\n",
    "    image_gray1 = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)\n",
    "    image_gray2 = cv2.cvtColor(image2, cv2.COLOR_BGR2GRAY)\n",
    "    diff, _ = compare_ssim(image_gray1, image_gray2, full=True)\n",
    "    return diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting frame0159.png    \n",
      "Deleting frame0160.png    \n",
      "Deleting frame0444.png    \n",
      "Deleting frame0469.png    \n",
      "Deleting frame0473.png    \n",
      "Deleting frame0477.png    \n",
      "Deleting frame0481.png    \n",
      "Deleting frame0493.png    \n",
      "Deleting frame0505.png    \n",
      "Deleting frame0506.png    \n",
      "Deleting frame0507.png    \n",
      "Deleting frame0508.png    \n",
      "Deleting frame0509.png    \n",
      "Deleting frame0513.png    \n",
      "Deleting frame0518.png    \n",
      "Deleting frame0519.png    \n",
      "Deleting frame0520.png    \n",
      "Deleting frame0521.png    \n",
      "Deleting frame0522.png    \n",
      "Deleting frame0525.png    \n",
      "Deleting frame0526.png    \n",
      "Deleting frame0527.png    \n",
      "Deleting frame0532.png    \n",
      "Done Checking Frames           \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def remove_duplicates(folder_name):\n",
    "    files=sorted(os.listdir(str(folder_name)))\n",
    "    files=files[1:]\n",
    "    for i in range(len(files)-1):\n",
    "        #print(files[i])#, end=\"\\r\")\n",
    "        print(files[i] + \"             \", end=\"\\r\")\n",
    "        image1 = cv2.imread(folder_name+'/'+files[i])\n",
    "        image2 = cv2.imread(folder_name+'/'+files[i+1])\n",
    "        diff = compare_images(image1, image2)\n",
    "        if diff > 0.99:\n",
    "            print(\"Deleting \" + files[i])\n",
    "            os.remove(folder_name+'/'+files[i])\n",
    "    print(\"Done Checking Frames           \")\n",
    "    print()\n",
    "\n",
    "remove_duplicates(\"video_0001\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install pickle5\n",
    "import pickle5 as pickle\n",
    "import pandas as pd\n",
    "\n",
    "with open('jaad_database.pkl', 'rb') as pickle_file:\n",
    "    pickle_data = pickle.load(pickle_file)\n",
    "\n",
    "labels = pd.DataFrame(data=pickle_data)\n",
    "labels['video_0001']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V8Bqr3D6ERcw"
   },
   "source": [
    "# FastAPI Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wFehIelzjo0E"
   },
   "outputs": [],
   "source": [
    "app = FastAPI()\n",
    "\n",
    "@app.on_event(\"startup\")\n",
    "def start_wandb(string_input=\"4B June 2021 Capstone\"):\n",
    "   init_wandb(project_name=string_input)\n",
    "   return {'message': ('Weights and Balances Started as project: ' + wandb_project)}\n",
    "\n",
    "@app.get('/')\n",
    "def index():\n",
    "    return {'message': 'This is the homepage of the model, add \\'/docs\\' to the end of the URL to access FastAPI to make predictions with the model'}\n",
    "\n",
    "@app.get('/reload_model')\n",
    "async def reload_model():\n",
    "   global model\n",
    "   model = model = tf.keras.models.load_model(BUCKET + f'/{model_dir}')\n",
    "   return {'message': 'Model on GCP reloaded at ' + BUCKET + '/' + model_dir}\n",
    "\n",
    "@app.get('/change_model')\n",
    "async def change_model(string_input):\n",
    "   global model_dir\n",
    "   model_dir = str(string_input)\n",
    "   model = tf.keras.models.load_model(BUCKET + f'/{model_dir}')\n",
    "   return {'message': 'Model on GCP loaded from ' + BUCKET + '/' + model_dir, 'warning': 'This function doesn\\'t currently check for file existence at location'}\n",
    "\n",
    "@app.post('/predict_single')\n",
    "async def predict_api(file: UploadFile = File(...)):\n",
    "    extension = file.filename.split(\".\")[-1] in (\"jpg\", \"jpeg\", \"png\")\n",
    "    if not extension:\n",
    "        return \"Image must be jpg or png format!\"\n",
    "    image = read_imagefile(await file.read())\n",
    "    prediction = run_predict_single(image)\n",
    "    prediction = str(prediction)\n",
    "    print(prediction)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4SAjBQPcFQlK"
   },
   "source": [
    "# Run Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HhmlEVYQFQRk",
    "outputId": "0819598b-d56a-443b-e6ae-0e54f2133bc5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [64]\n",
      "INFO:     Waiting for application startup.\n",
      "ERROR:    Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/starlette/routing.py\", line 540, in lifespan\n",
      "    async for item in self.lifespan_context(app):\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/starlette/routing.py\", line 481, in default_lifespan\n",
      "    await self.startup()\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/starlette/routing.py\", line 518, in startup\n",
      "    handler()\n",
      "  File \"<ipython-input-9-fa9cff6b7f9b>\", line 5, in start_wandb\n",
      "    wandb.init(project=\"mlops-midterm\", sync_tensorboard=True)\n",
      "NameError: name 'wandb' is not defined\n",
      "\n",
      "ERROR:    Application startup failed. Exiting.\n"
     ]
    }
   ],
   "source": [
    "nest_asyncio.apply()\n",
    "uvicorn.run(app, port=8000)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Capstone.ipynb",
   "provenance": []
  },
  "environment": {
   "name": "common-cu110.m79",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu110:m79"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
