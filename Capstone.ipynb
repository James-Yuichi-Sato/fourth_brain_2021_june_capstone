{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j-wh0-R8nIvS"
   },
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "S_kef3gWlciz"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install --upgrade fastapi ffmpeg uvicorn python-multipart tensorflow-gpu scikit-image imutils wandb tensorflow_hub Pillow\n",
    "\n",
    "from fastapi import FastAPI, File, UploadFile\n",
    "from skimage.metrics import structural_similarity as compare_ssim\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import label_map_util\n",
    "import ffmpeg, shutil\n",
    "\n",
    "from google.cloud import storage\n",
    "import nest_asyncio, uvicorn, os, pathlib\n",
    "\n",
    "import cv2, wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yFaiDWdISXGf"
   },
   "source": [
    "# Set Up Google Cloud Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QMbfPM4GSgYt"
   },
   "source": [
    "## Set Up Google Cloud Project and Model Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "2bjDmnc5SbHq"
   },
   "outputs": [],
   "source": [
    "project = 'mlops-content1' # Cloud Project Name\n",
    "location = 'james-mlops-capstone' # Model Storage Bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h4nk8gw3VHwz"
   },
   "source": [
    "## Create Storage Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "R5BDNjqAVKun"
   },
   "outputs": [],
   "source": [
    "storage_client = storage.Client.from_service_account_json('gcp-key.json')\n",
    "\n",
    "bucket = storage_client.bucket(location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ONo4xnfLS0wX"
   },
   "source": [
    "## Double Check Cloud Bucket (Development Code Only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m4yUDLqHS0VH",
    "outputId": "40c1f26c-4235-441e-d2d0-5a7db2c34e87"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "blobs = storage_client.list_blobs(location)\n",
    "for blob in blobs:\n",
    "    print(blob.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iZCVJpk3H3Ij"
   },
   "source": [
    "# WandB Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "6JDy6oOTH5v8"
   },
   "outputs": [],
   "source": [
    "def init_wandb(project_name):\n",
    "   global wandb_project\n",
    "   wandb_project = str(project_name)\n",
    "   wandb.init(project=wandb_project, sync_tensorboard=True)\n",
    "   return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KxBHkID8TdsN"
   },
   "source": [
    "# Set File Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "q44f0uKITftp"
   },
   "outputs": [],
   "source": [
    "def set_folder_location(in_location):\n",
    "    global location \n",
    "    location = str(in_location)\n",
    "    global bucket\n",
    "    bucket = storage_client.bucket(location)\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ia1dFbYETDJB"
   },
   "source": [
    "# Split Video to Frames and Upload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Video to Local Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_video(video_name):\n",
    "    print(\"Downloading: \" + str(video_name))\n",
    "    blob = bucket.blob(video_name)\n",
    "    blob.download_to_filename(video_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Break down video to frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_video_frames(video_name):\n",
    "    print(\"Splitting: \" + str(video_name))\n",
    "    folder = video_name[:-4]\n",
    "    try:\n",
    "        shutil.rmtree(str(folder))\n",
    "    except:\n",
    "        pass\n",
    "    os.mkdir(str(folder))\n",
    "    \n",
    "    video_capture = cv2.VideoCapture(str(video_name))\n",
    "    saved_frame_name = 1\n",
    "\n",
    "    while True:\n",
    "        print(\"Frame: \" + format(saved_frame_name, '05d'), end=\"\\r\")\n",
    "        success, frame = video_capture.read()\n",
    "\n",
    "        if success:\n",
    "            cv2.imwrite(f\"{str(folder)}/frame{format(saved_frame_name, '05d')}.png\", frame)\n",
    "            saved_frame_name += 1\n",
    "        else:\n",
    "            break\n",
    "    print(\"Done                       \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload Video Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_frames_from_folder(folder_name):\n",
    "    files=sorted(os.listdir(str(folder_name)))\n",
    "    #files=files[1:]\n",
    "    \n",
    "    print(\"Uploading Frames\")\n",
    "    for i in range(len(files)):\n",
    "        print(files[i] + \"             \", end=\"\\r\")\n",
    "        blob = bucket.blob(folder_name + \"/\" + files[i])\n",
    "        blob.upload_from_filename(folder_name + \"/\" + files[i])\n",
    "        \n",
    "    print(\"Done Uploading               \", end=\"\\r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SSIM Compare Video Frames for Novel Frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Blurry Images from Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Blurriness using Laplacian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variance_of_laplacian(image):\n",
    "    # compute the Laplacian of the image and then return the focus\n",
    "    # measure, which is simply the variance of the Laplacian\n",
    "    return cv2.Laplacian(image, cv2.CV_64F).var()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Blurry Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_blurry_images(folder_name):\n",
    "    files=sorted(os.listdir(str(folder_name)))\n",
    "    files=files[1:]\n",
    "    \n",
    "    blurriness = np.zeros(len(files))\n",
    "    \n",
    "    print(\"Calculating Average Blurriness\")\n",
    "    for i in range(len(files)):\n",
    "        print(files[i] + \"             \", end=\"\\r\")\n",
    "        img=cv2.imread(folder_name+'/'+files[i])\n",
    "        img_gray=cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        blurriness[i]=variance_of_laplacian(img_gray)\n",
    "        wandb.log({'Individual Laplacian': blurriness[i]})\n",
    "    \n",
    "    median_blur = np.median(blurriness)\n",
    "    wandb.log({'Batch Median Laplacian': median_blur})\n",
    "    print(\"Median Blur (Laplacian Variance): \" + str(median_blur))\n",
    "    blur_cutoff = median_blur*1.05 #+ ((1-average_blur)*0.1)\n",
    "    print(\"Blur Cutoff (Laplacian Variance): \" + str(blur_cutoff))\n",
    "    \n",
    "    print(\"Removing Noisy Images\")\n",
    "    \n",
    "    count = 0\n",
    "    for i in range(len(files)):\n",
    "        if blurriness[i] > blur_cutoff:\n",
    "            #print(\"Deleting \" + files[i] + \" - Laplacian Noisiness: \" + str(blurriness[i]))\n",
    "            os.remove(folder_name+'/'+files[i])\n",
    "            count += 1\n",
    "    blur_ratio = count/len(files)\n",
    "    wandb.log({'Noisy Frame Ratio': blur_ratio})\n",
    "    print(\"Done Checking Frames                  \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deduplicate Similar Frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Similarity Between Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_images(image1, image2):\n",
    "    image_gray1 = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)\n",
    "    image_gray2 = cv2.cvtColor(image2, cv2.COLOR_BGR2GRAY)\n",
    "    diff, _ = compare_ssim(image_gray1, image_gray2, full=True)\n",
    "    return diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(folder_name):\n",
    "    files=sorted(os.listdir(str(folder_name)))\n",
    "    files=files[1:]\n",
    "    print(\"Removing Duplicate and Highly Similar Frames\\nCalculating Frame Similarities\")\n",
    "    \n",
    "    diff = np.zeros(len(files)-1)    \n",
    "    \n",
    "    for i in range(len(files)-1):\n",
    "        image1 = cv2.imread(folder_name+'/'+files[i])\n",
    "        image2 = cv2.imread(folder_name+'/'+files[i+1])\n",
    "        diff[i] = compare_images(image1, image2)\n",
    "        wandb.log({'Individual Frame Similarities': diff[i]})\n",
    "        print(str(diff[i]), end=\"\\r\")\n",
    "    \n",
    "    median_diff = np.median(diff)\n",
    "    wandb.log({'Batch Median Frame Similarity': median_diff})\n",
    "    \n",
    "    diff_cutoff = median_diff*1.05\n",
    "    \n",
    "    if diff_cutoff < 0.95:\n",
    "        diff_cutoff = 0.95\n",
    "        \n",
    "    print(\"Similarity Cutoff (OpenCV Compare Images): \" + str(diff_cutoff))\n",
    "    print(\"Removing Duplicate Images\")\n",
    "    \n",
    "    count = 0\n",
    "    for i in range(len(diff)):\n",
    "        if diff[i] > 0.99:\n",
    "            #print(\"Deleting \" + files[i] + \" - Similarity: \" + str(diff[i]), end=\"\\r\")\n",
    "            os.remove(folder_name+'/'+files[i])\n",
    "            wandb.log({'Duplicates Similarity': diff})\n",
    "            count += 1\n",
    "        \n",
    "    duplicate_ratio = count/len(files)\n",
    "    wandb.log({'Batch Duplicate Remove Ratio': duplicate_ratio})\n",
    "    print(\"Done Checking Frames, \" + str(count) + \" frames removed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Insight into the Dataset using Faster RCNN Resnet50 COC0 2018/01/28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-17 17:11:58.636836: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-17 17:11:58.645020: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-17 17:11:58.645874: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-17 17:11:58.647080: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-09-17 17:11:58.647974: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-17 17:11:58.648664: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-17 17:11:58.649272: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-17 17:11:59.196524: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-17 17:11:59.197259: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-17 17:11:59.197848: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-17 17:11:59.198387: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13803 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
      "2021-09-17 17:11:59.251075: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    }
   ],
   "source": [
    "model_url = 'http://download.tensorflow.org/models/object_detection/faster_rcnn_resnet50_coco_2018_01_28.tar.gz'\n",
    "base_url = os.path.dirname(model_url)+\"/\"\n",
    "model_file = os.path.basename(model_url)\n",
    "model_name = os.path.splitext(os.path.splitext(model_file)[0])[0]\n",
    "model_dir = tf.keras.utils.get_file(fname=model_name, origin=base_url + model_file, untar=True)\n",
    "model_dir = pathlib.Path(model_dir)/\"saved_model\"\n",
    "model = tf.saved_model.load(str(model_dir))\n",
    "model = model.signatures['serving_default']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_LABELS = [\"\", \"person\", \"bicycle\", \"car\", \"motorcycle\", \"airplane\", \"bus\", \"train\", \"truck\", \"boat\", \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\", \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\", \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\", \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\", \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\", \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"couch\", \"potted plant\", \"bed\", \"dining table\", \"toilet\", \"tv\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\", \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\", \"teddy bear\", \"hair drier\", \"toothbrush\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_objects(image):\n",
    "    img = Image.open(image)\n",
    "    input_tensor = tf.convert_to_tensor(img)\n",
    "    input_tensor = input_tensor[tf.newaxis,...]\n",
    "    output_dict = model(input_tensor)\n",
    "    num_detections = int(output_dict.pop('num_detections'))\n",
    "    output_dict = {key:value[0, :num_detections].numpy() for key,value in output_dict.items()}\n",
    "    classes = output_dict['detection_classes'].astype(np.int64)\n",
    "    class_names = [None] * len(classes)\n",
    "    for i in range(len(classes)):\n",
    "        class_names[i]=CLASS_LABELS[classes[i]]\n",
    "    wandb.log({'Detections per Image': num_detections})\n",
    "    return class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_file(folder_name):\n",
    "    for file in sorted(os.listdir(folder_name)):\n",
    "        total_location = folder_name+\"/\"+file\n",
    "        classes = detect_objects(total_location)\n",
    "        with open(total_location+\".txt\", \"w\") as text_file:\n",
    "            text_file.write(str(classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full Video Analysis and Upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_video(video_name):\n",
    "    video_name = str(video_name)\n",
    "    folder_name = str(video_name)[:-4]\n",
    "    download_video(video_name)\n",
    "    split_video_frames(video_name)\n",
    "    remove_blurry_images(folder_name)\n",
    "    remove_duplicates(folder_name)\n",
    "    detect_file(folder_name)\n",
    "    upload_frames_from_folder(folder_name)\n",
    "    shutil.rmtree(folder_name)\n",
    "    os.remove(video_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze Entire Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_entire_bucket():\n",
    "    blobs = storage_client.list_blobs(location)\n",
    "    for blob in blobs:\n",
    "        clean_video(blob.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V8Bqr3D6ERcw"
   },
   "source": [
    "# FastAPI Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "wFehIelzjo0E"
   },
   "outputs": [],
   "source": [
    "app = FastAPI()\n",
    "\n",
    "@app.on_event(\"startup\")\n",
    "def start_wandb():\n",
    "    init_wandb(location)\n",
    "    return {'message': ('Weights and Balances Started as project: ' + wandb_project)}\n",
    "\n",
    "@app.get('/')\n",
    "def index():\n",
    "    return {'message': 'This is the homepage of the model, add \\'/docs\\' to the end of the URL to access FastAPI to make predictions with the model'}\n",
    "\n",
    "@app.get('/set_gcp_location')\n",
    "def set_gcp_location(string_input):\n",
    "    set_folder_location(str(string_input))\n",
    "    return {'message': ('GCP Location Set to: ' + location)}\n",
    "\n",
    "@app.get('/clean_single_video')\n",
    "async def single_clean(string_input):\n",
    "    clean_video(str(string_input))\n",
    "    return {'message': ('Video: ' + str(string_input) + ' cleaned and uploaded to gs://' + location + \"/\" + str(string_input))}\n",
    "\n",
    "@app.get('/clean_bucket')\n",
    "async def full_clean():\n",
    "    clean_entire_bucket()\n",
    "    return {'message': ('Bucket: ' + location + ' cleaned and uploaded to gs://' + location)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4SAjBQPcFQlK"
   },
   "source": [
    "# Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HhmlEVYQFQRk",
    "outputId": "0819598b-d56a-443b-e6ae-0e54f2133bc5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter:  ········································\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/jupyter/.netrc\n",
      "INFO:     Started server process [29949]\n",
      "INFO:     Waiting for application startup.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjamesysato\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.2<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">bumbling-planet-29</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/jamesysato/james-mlops-capstone\" target=\"_blank\">https://wandb.ai/jamesysato/james-mlops-capstone</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/jamesysato/james-mlops-capstone/runs/33ngin6s\" target=\"_blank\">https://wandb.ai/jamesysato/james-mlops-capstone/runs/33ngin6s</a><br/>\n",
       "                Run data is saved locally in <code>/home/jupyter/wandb/run-20210917_171226-33ngin6s</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n"
     ]
    }
   ],
   "source": [
    "nest_asyncio.apply()\n",
    "wandb.login(relogin=True)\n",
    "uvicorn.run(app, host='0.0.0.0', port=8000)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Capstone.ipynb",
   "provenance": []
  },
  "environment": {
   "name": "common-cu110.m79",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu110:m79"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
